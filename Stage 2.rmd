---
title: "Stage 2"
author: "Vanessa Stechert"
output: html_document
---

```{r setup, include=FALSE}
# load packages
library(dplyr)
library(wordcloud)
library(tidytext)
library(ggrepel)
library(smacof)
library(ggfortify)
library(ggthemes)
library(quanteda)
library(tm)
library(anacor)
library(stringi)
library(stringr)
library(igraph)
library(dendextend)
library(circlize)
library(SnowballC)
#library(FactoMineR)
library(factoextra)
#library(qdap)
```

```{r}
# Standard setups as recommended in Kwartel
options(stringsAsFactors=F)
Sys.setlocale('LC_ALL','C')

```


```{r}
#load data
load("amazon_apple_cleaned_reviews.Rdata")

hotel.df <- reviews_df
View(hotel.df)

```

```{r}
#part of the drawing algorithm is random. It is always good when coding to be able to replicate what you do. To achieve this, we fix what is called the seed of the random number generator. Please see the difference for different seeds

wordcount_all <- hotel.df %>% unnest_tokens(word,Description) %>% count(word, sort=TRUE)



set.seed(1223)
wordcloud(words = wordcount_all$word, freq = wordcount_all$n, min.freq = 1000,
          max.words=70, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))


set.seed(1234)
wordcloud(words = wordcount_all$word, freq = wordcount_all$n, min.freq = 1000,
          max.words=70, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```


```{r}
# Histogram output of wordcount
wordcount_all %>% 
  mutate(word = reorder(word,n)) %>% 
  top_n(20, word) %>%
  ggplot(aes(word,n)) +  
  geom_col() + 
  labs(x = NULL, y = "Number of occurences") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Word Frequency Histogram")

```


```{r}
#Dataframe with happy reviews
wordcount_happy <- hotel.df %>% 
  unnest_tokens(word,Description) %>% 
  filter(Rating==c("4","5")) %>%
  count(word, sort=TRUE)

names(wordcount_happy)[2] <- "n_happy"
```

```{r}
wordcount_happy %>% 
  mutate(word = reorder(word,n_happy)) %>% 
  top_n(20, word) %>%
  ggplot(aes(word,n_happy)) +  
  geom_col() + 
  labs(x = NULL, y = "Number of occurences") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Word Frequency Histogram Happy")
```

```{r}
#Dataframe with not happy reviews
wordcount_unhappy <- hotel.df %>% 
  unnest_tokens(word,Description) %>% 
  filter(Rating==c("1","2","3")) %>%
  count(word, sort=TRUE)

names(wordcount_unhappy)[2] <- "n_unhappy"

```


```{r}
wordcount_unhappy %>% 
  mutate(word = reorder(word,n_unhappy)) %>% 
  top_n(20, word) %>%
  ggplot(aes(word,n_unhappy)) +  
  geom_col() + 
  labs(x = NULL, y = "Number of occurences") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Word Frequency Histogram Unhappy")
```

switching to document term matrix (this is the dfm (document frequency) format in quanteda )

```{r}
corpus <- corpus(hotel.df, docid_field = "X", text_field = "Description",  metacorpus = NULL, compress = TRUE)




hotel.dfm <- dfm(corpus)
wordfreqs <- colSums(as.matrix(hotel.dfm)) 
wordfreqs <- data.frame(word = names(wordfreqs), n=wordfreqs)

wordfreqs %>%
  mutate(word = reorder(word,n)) %>% 
  top_n(20, word) %>%
  ggplot(aes(word,n)) +  
  geom_col() + 
  labs(x = NULL, y = "Number of occurences") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Word Frequency Histogram ")

```

```{r}

corpus <- corpus(hotel.df, docid_field = "X", text_field = "Description",  metacorpus = NULL, compress = TRUE)
hotel.dfm <- dfm(corpus)
docfreqs <- docfreq(hotel.dfm) %>% sort(decreasing = TRUE)
docfreqs <- data.frame(word = names(docfreqs), n_docs=docfreqs)

docfreqs %>%
  mutate(word = reorder(word,n_docs)) %>% 
  top_n(20, word) %>%
  ggplot(aes(word,n_docs)) +  
  geom_col() + 
  labs(x = NULL, y = "Number of occurences") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Document Frequency Histogram ")

```

```{r}
tf_idf_table <- merge(docfreqs, wordcount_all)

tf_idf_table$tf_idf <- tf_idf_table$n/tf_idf_table$n_docs

tf_idf_table<-tf_idf_table[order(-tf_idf_table$tf_idf),]
```

```{r}

tf_idf_table %>%
  mutate(word = reorder(word,tf_idf)) %>% 
  top_n(20, tf_idf) %>%
  ggplot(aes(word,tf_idf)) +  
  geom_col() + 
  labs(x = NULL, y = "tf_idf") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("TF-IDF value ")

```

```{r}
both_un_happy <- merge(wordcount_unhappy, wordcount_happy)

both_un_happy$ratio <- both_un_happy$n_happy / both_un_happy$n_unhappy

both_un_happy<-both_un_happy[order(-both_un_happy$ratio),]

```

```{r}

both_un_happy %>%
  mutate(word = reorder(word,ratio)) %>% 
  top_n(20, ratio) %>%
  ggplot(aes(word,ratio)) +  
  geom_col() + 
  labs(x = NULL, y = "ratio") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Relatively most frequent words in happy ")



both_un_happy %>%
  mutate(word = reorder(word,-ratio)) %>% 
  top_n(-20, ratio) %>%
  ggplot(aes(word,ratio)) +  
  geom_col() + 
  labs(x = NULL, y = "ratio") + 
  coord_flip() + 
  theme(text = element_text(size = 17)) + 
  ggtitle("Relatively most frequent words in unhappy ")
```
```{r}
review_tdm <- hotel.df %>% unnest_tokens(word,Description) %>%count(word,Rating,sort=TRUE) %>%ungroup()%>%cast_tdm(word,Rating,n)

#a comparison cloud focuses on the differences in frequencies across the two groups. Words that occur very often in both are not shown as prominently

comparison.cloud(as.matrix(review_tdm), scale=c(3,0.5), random.order=FALSE, colors = c("indianred3","lightsteelblue3"),
 max.words=30, rot.per = 0.3)

commonality.cloud(as.matrix(review_tdm), scale=c(3,0.5), random.order=FALSE, colors=brewer.pal(8, "Dark2"),
                  max.words=30, rot.per = 0.3)

```

```{r} 
#an alternative way of getting the total 
hotel.dfm <- dfm(corpus) 
counts <- colSums(as.matrix(hotel.dfm)) 
sortedcount <- counts %>% sort(decreasing=TRUE)
sortednames <- names(sortedcount)

```


```{r}
#nwords<-200
#subset_words<-as.matrix(sortedcount[1:nwords])
```


```{r}
reviews_corp <- corpus(hotel.df, docid_field = "X", text_field = "Description")

# feature cooccurrence matrix : fcm()
Burt_fcm <- fcm(x = reviews_corp, context = "document", count = "boolean", tri=FALSE)


#Need number of documents with each word on the diagonal
hotel.dfm <- dfm(corpus) # get document frequency matrix

# Does not seem to work due to RAM error
counts <- colSums(as.matrix(hotel.dfm)>0) # count how often frequency is positive
Burt_fcm <- as.matrix(Burt_fcm)
diag(Burt_fcm) <- counts

```

```{r}
distances <- sim2diss(Burt_fcm, method = "cooccurrence") # Transform similarities to distances.
distances[1:15,1:15]
min(distances) #check whethet minimum distance is positive. Sometimes the counting procedure did something unexpected.
max(distances) #check whethet minimum distance is positive. Sometimes the counting procedure did something unexpected.
MDS_map <- smacofSym(distances) # run the routine that finds the best matching coordinates in a 2D mp given the distances
ggplot(as.data.frame(MDS_map$conf), aes(D1, D2, label = rownames(MDS_map$conf))) +
     geom_text(check_overlap = TRUE) + theme_minimal(base_size = 15) + xlab('') + ylab('') +
     scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL)
# the conf element in the MDS output contains the coordinatis with as names D1 and D2.

```
```{r}
Burt_fcm <- fcm(x = reviews_corp, context = "window", window=2, count = "boolean", tri=FALSE)

Burt_fcm<-Burt_fcm[sortednames,sortednames]

diag(Burt_fcm) <- counts[sortednames]
Burt_fcm[1:15,1:15]
distances <- sim2diss(Burt_fcm, method = "cooccurrence") # Transform similarities to distances.
min(distances) #check whethet minimum distance is positive. Sometimes the counting procedure did something unexpected.
max(distances) #check whethet minimum distance is positive. Sometimes the counting procedure did something unexpected.
MDS_map <- smacofSym(distances) # run the routine that finds the best matching coordinates in a 2D mp given the distances
ggplot(as.data.frame(MDS_map$conf), aes(D1, D2, label = rownames(MDS_map$conf))) +
     geom_text(check_overlap = TRUE) + theme_minimal(base_size = 15) + xlab('') + ylab('') +
     scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL)
# the conf element in the MDS output contains the coordinatis with as names D1 and D2.

```
```{r}
Burt_fcm <- fcm(x = reviews_corp, context = "window", window=4, count = "boolean", tri=FALSE)

Burt_fcm<-Burt_fcm[sortednames,sortednames]

diag(Burt_fcm) <- counts[sortednames]
Burt_fcm[1:15,1:15]
distances <- sim2diss(Burt_fcm, method = "cooccurrence") # Transform similarities to distances.
min(distances) #check whethet minimum distance is positive. Sometimes the counting procedure did something unexpected.
max(distances) #check whethet minimum distance is positive. Sometimes the counting procedure did something unexpected.
MDS_map <- smacofSym(distances) # run the routine that finds the best matching coordinates in a 2D mp given the distances
ggplot(as.data.frame(MDS_map$conf), aes(D1, D2, label = rownames(MDS_map$conf))) +
     geom_text(check_overlap = TRUE) + theme_minimal(base_size = 15) + xlab('') + ylab('') +
     scale_y_continuous(breaks = NULL) + scale_x_continuous(breaks = NULL)
# the conf element in the MDS output contains the coordinatis with as names D1 and D2.

```

```{r}
load("amazon_apple_cleaned_reviews.Rdata")
```


```{r}
pca_results <- prcomp(t(tdm), scale = FALSE, rank. = 50) # waarom zetten we scale op FALSE en niet op TRUE? 
pca_results_backup <- pca_results

```

```{r}
pca_results_backup -> pca_results
 
ncomp<-6
rawLoadings     <- pca_results$rotation[,1:ncomp] %*% diag(pca_results$sdev, ncomp, ncomp)
rotated <- varimax(rawLoadings)
pca_results$rotation <- rotated$loadings
pca_results$x <- scale(pca_results$x[,1:ncomp]) %*% rotated$rotmat


print("PCA finished")

```




```{r}
#select the most important words per rotated dimension

j<-1
toplist <- abs(pca_results$rotation[,j]) %>% sort(decreasing=TRUE) %>% head(10)
topwords <- t(names(toplist))
for (j in ncomp){
toplist <--abs(pca_results$rotation[,j]) %>% sort(decreasing=TRUE) %>% head(10)
topwords <-cbind( t(names(toplist)),topwords)
  }


```


```{r}


pca_results_small <- pca_results

pca_results_small$rotation<-pca_results_small$rotation[unique(t(topwords)),1:2]

pca_results_small$x <- pca_results_small$x[1:100,1:2] # individuals and factors
#pca_results_small$rotation <- pca_results_small$rotation[1:10,1:10] # individuals and factors
pca_results_small$center <- pca_results_small$center[1:2] # individuals and factors


pca_results <- pca_results_small
```

```{r}
fviz_screeplot(pca_results,ncp=30)
```
```{r}
axeslist=c(1,2)

fviz_pca_ind(pca_results, axes = axeslist, 
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

```{r}
fviz_pca_ind(pca_results, axes = axeslist,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = FALSE,     # Avoid text overlapping
             geom = "point" # shows only points and no lables
             )
```

```{r}
axeslist <- c(1, 2)
fviz_pca_var(pca_results, axes=axeslist,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

```
```{r}

fviz_pca_biplot(pca_results, repel = TRUE,axes=axeslist,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969"  # Individuals color
                )

fviz_pca_biplot(pca_results, repel = TRUE,axes=axeslist,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969"  # Individuals color
,               geom = "point" # shows only points and no lables
                )
```
```{r}

#plot individuals by score/evaluation???
groups <- as.factor(hotel.df[1:100, 'Rating' ])
fviz_pca_ind(pca_results, axes=c(1,2),
             col.ind = groups, # color by groups
             # palette = c("#00AFBB",  "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             ellipse.type = "confidence",
             legend.title = "Groups",
             repel = TRUE,
             geom = "point" # shows only points and no lables
             )
```



