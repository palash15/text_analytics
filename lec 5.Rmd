---
title: "Word embeddings"
author: "Dennis Fok/Bas Donkers"
date: "March, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tidyr)
library(text2vec)
library(tidytext)
library(ggplot2)
library(SnowballC)
```

Obtaining and organizing the data
```{r}
options(stringsAsFactors = FALSE)
reviews_df <- read.csv("C:/Users/Palas/Documents/EUR/Text Analytics/Amazon_Apple_Phone.csv")
names(reviews_df)[names(reviews_df) == "Reviews"] <- "Description"

reviews_df$Description <- as.character(reviews_df$Description) %>%
                            tolower() %>%
                            {gsub(":( |-|o)*\\("," SADSMILE ", .)} %>%       # Find :( or :-( or : ( or :o(
                            {gsub(":( |-|o)*\\)"," HAPPYSMILE ", .)} %>%     # Find :) or :-) or : ) or :o)
                            {gsub("(\"| |\\$)-+\\.-+"," NUMBER", .)} %>%     # Find numbers
                            {gsub("(-+:)*-+ *am"," TIME_AM", .)} %>%         # Find time AM
                            {gsub("(-+:)*-+ *pm"," TIME_PM", .)} %>%         # Find time PM
                            {gsub("-+:-+","TIME", .)} %>%                    # Find general time
                            {gsub("( |\\$)--+"," NUMBER", .)} %>%            # Find remaining numbers
#                            {gsub("-"," ", .)} %>%                           # Remove all -
#                            {gsub("\"+"," ", .)} %>%                         # Remove all "
#                            {gsub(";+"," ", .)} %>%                          # Remove excess ;
#                            {gsub("\\.+","\\.", .)} %>%                      # Remove excess .
                            {gsub("[[:punct:]]", " ",.)} %>% 
                            {gsub(" +"," ", .)} %>%                          # Remove excess spaces
#                            {gsub(" ate"," eat", .)} %>%        # stem specific word
                            {gsub("theeatr","theatr", .)} %>%        # stem specific word
                            {gsub("theater","theatr", .)} %>%        # stem specific word
                            {gsub("avenue","av", .)} %>%        # stem specific word
                            {gsub("[sS]an [fF]rancisco","sf", .)} %>%        # abreviate city name
                            {gsub("[Nn][yY][cC]","ny", .)} %>%        # abreviate city name
                            {gsub("[nN]ew ?[yY]ork( ?city)?","ny", .)} %>%      # abreviate city name
                            {gsub("[Ii]phone","", .)} %>%
                            {gsub("[Pp]hone","", .)} %>%
                            {gsub("ðÿ ","", .)} %>%
                            {gsub("[Aa]pple ","", .)} %>%
                            {gsub("ll","", .)}
 
saved <- reviews_df
print("done")
```

Word stemming
```{r stem words} 
# here removing stop words, and stemming done
for (j in 1:nrow(reviews_df)) {
 tmp <- reviews_df[j,] %>% unnest_tokens(word, Description) %>% anti_join(stop_words, 
                                                                          by="word")
  stemmed <- wordStem(tmp[ , "word"], language = "porter")
  reviews_df[j, "stemmed_reviewtext"] <- paste(stemmed, collapse = " ")

}
print("done")
#reviews_df$stemmed_reviewtext <- reviews_df$Description
```

Pre-process and get TCM
```{r}
# create iterator over list of text items
it = itoken(reviews_df$stemmed_reviewtext)
```

```{r}
#create the vocabulary and remove infrequent words
vocabulary = create_vocabulary(it)
vocabulary = prune_vocabulary(vocabulary, term_count_min = 400)

#create vector version of the vocabulary: speeds up allocation/search process
v_vect = vocab_vectorizer(vocabulary)
tcm = create_tcm(it, v_vect, skip_grams_window = 8L) # create term co-occurrence matrix
```

Class 6 objects in R are mutable objects. You can run methods/models on them and they change content.
Step 1 is to create a model with a set of model configuration parameters.
```{r}
glove_model = GlobalVectors$new( x_max = 1000 , rank = 50)
```

# fit model and obtain results.
# note that the glove_model construct is now also changed!
```{r}
word_vectors = glove_model$fit_transform(tcm, n_iter = 200)
```

```{r}
word_vectors[1:10,1:10]
```


```{r}
similarity_matrix = sim2(word_vectors)
print("a sample of the similarity matrix across words ")
similarity_matrix[1:9,1:9]
nwords=nrow(similarity_matrix)
```

```{r}
top_bottom=c(1:10,(nwords-9):nwords)
```


```{r}
cc=sort(similarity_matrix[,"fix"], decreasing=TRUE)
cc[top_bottom]
```

```{r}
cc=sort(similarity_matrix[,"screen"], decreasing=TRUE)
cc[top_bottom]
```

```{r}
cc=sort(similarity_matrix[,"featur"], decreasing=TRUE)
cc[top_bottom]
```


```{r}

cc=sort(similarity_matrix[,"state"], decreasing=TRUE)
head(cc,10); tail (cc,10)
```
```{r}
cc=sort(similarity_matrix[,"stai"], decreasing=TRUE)
head(cc,10); tail (cc,10)
```
```{r}
cc=sort(similarity_matrix[,"ny"], decreasing=TRUE)
head(cc,10); tail (cc,10)
```

```{r}
comparator = word_vectors["ny",]+word_vectors["sf",]
similarities = sim2(word_vectors,t(comparator))
ranking = sim2(word_vectors,t(comparator))%>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))
```
```{r}
comparator = word_vectors["broadwai",]
ranking = sim2(word_vectors,t(comparator))%>% order(decreasing=TRUE)
print(vocabulary$term[ranking[top_bottom]])

```


```{r}
comparator = word_vectors["ny",]+word_vectors["stai",]
similarities = sim2(word_vectors,t(comparator))
ranking = similarities %>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))
```

```{r}
comparator = word_vectors["ny",]+word_vectors["stai",]+word_vectors["at",]  
similarities = sim2(word_vectors,t(comparator))
ranking = similarities %>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))
```


```{r}
comparator = word_vectors["carpet",]
ranking = sim2(word_vectors,t(comparator))%>% order(decreasing=TRUE)
print(vocabulary$term[ranking[top_bottom]])
```
```{r}
comparator = word_vectors["view",]
ranking = sim2(word_vectors,t(comparator))%>% order(decreasing=TRUE)
print(vocabulary$term[ranking[top_bottom]])

```

```{r}
comparator = word_vectors["view",]+word_vectors["river",]
ranking = sim2(word_vectors,t(comparator))%>% order(decreasing=TRUE)
print(vocabulary$term[ranking[top_bottom]])
```


```{r}

comparator = word_vectors["fisherman",]-word_vectors["sf",]+word_vectors["ny",]
ranking = sim2(word_vectors,t(comparator))%>% order(decreasing=TRUE)
print(vocabulary$term[ranking[top_bottom]])
```

```{r}

comparator = word_vectors["chinatown",]-word_vectors["ny",]+word_vectors["sf",]
similarities = sim2(word_vectors,t(comparator))
ranking = similarities %>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))
```




```{r}
comparator = (word_vectors["broadwai",]+word_vectors["chinatown",])/2-word_vectors["ny",]+word_vectors["sf",]
ranking = sim2(word_vectors,t(comparator))%>% order(decreasing=TRUE)
print(vocabulary$term[ranking[top_bottom]])
```
```{r}
comparator = word_vectors["love",]  - word_vectors["best",]
similarities = sim2(word_vectors,t(comparator))
ranking = similarities %>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))

```

```{r}
comparator = word_vectors["love",]  - word_vectors["good",]
similarities = sim2(word_vectors,t(comparator))
ranking = similarities %>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))

```

```{r}
comparator = word_vectors["westin",] 
similarities = sim2(word_vectors,t(comparator))
ranking = similarities %>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))

feature_vec=c("love","amaz","spaciou","great","dirti","clean","friend","servic")
similarities[feature_vec,]
```
```{r}
comparator = word_vectors["marriott",]
similarities = sim2(word_vectors,t(comparator))
ranking = similarities %>% order(decreasing=TRUE)
print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))

feature_vec=c("love","amaz","spaciou","great","dirti","clean","friend","servic")
similarities[feature_vec,]
```

```{r}
comparator = word_vectors["westin",]  - word_vectors["marriott",]
similarities = sim2(word_vectors,t(comparator))
# ranking = similarities %>% order(decreasing=TRUE)
# print(as.data.frame(similarities[ranking[top_bottom]], row.names = vocabulary$term[ranking[top_bottom]]))
feature_vec=c("amaz","great","love","near","dirti","view","clean","staff","friend","servic")
print(as.data.frame(similarities[feature_vec,] ))
```

#word finder within vocabulary
```{r}
wordnumbers=grep("^chin.*",vocabulary$term)
vocabulary$term[wordnumbers]

wordnumbers=grep("chin.*",vocabulary$term)
vocabulary$term[wordnumbers]
```